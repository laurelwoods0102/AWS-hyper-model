{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598599689170",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 3196231680, 93292771632, 93293300344, ..., 92658792872,\n       92658792864, 92654987192], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "original = np.genfromtxt(\"../로그 데이터/SEG_SGEMM_result.txt\", delimiter=\"\\n\", dtype=np.int64)\n",
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, test_set = train_test_split(original, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculateDelta(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return np.array([X[i+1] - X[i] for i in range(int(len(X))-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseTokenizer(TransformerMixin):\n",
    "    def __init__(self, minimum_category_occurence=2, oov_token=-1):\n",
    "        self.minimum_category_occurence = minimum_category_occurence\n",
    "        self.oov_token = oov_token\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        mask = (pd.Series(X).value_counts() <= self.minimum_category_occurence)\n",
    "        noise_index = np.where(np.isin(X, mask.index[mask == True]))[0]\n",
    "        X[noise_index] = self.oov_token\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCategoryEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_counts = pd.Series(X).value_counts()\n",
    "        self.vocab_size = len(X_counts)\n",
    "        self.word_index = X_counts.index\n",
    "        self.vocabulary = {X_counts.index[i]:i for i in range(self.vocab_size)}\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return np.array([self.vocabulary[X[i]] for i in range(len(X))])\n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        return np.array([self.word_index[X[i]] for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([   0,    0,    0, ..., 1918, 1235, 1227])"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "SEG_pipeline = Pipeline([\n",
    "    ('calculate_delta', CalculateDelta()),\n",
    "    ('noise_tokenizer', NoiseTokenizer()),\n",
    "    ('sparse_category_encoder', SparseCategoryEncoder())\n",
    "])\n",
    "\n",
    "train_set = SEG_pipeline.fit_transform(data)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "48"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "train_set[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{-1: 0,\n 0: 1,\n 4096: 2,\n 909517620: 3,\n -909517620: 4,\n 8192: 5,\n -8: 6,\n -4096: 7,\n 8: 8,\n 12288: 9,\n 2416: 10,\n 16384: 11,\n 24: 12,\n 3520: 13,\n -12: 14,\n 64: 15,\n 6: 16,\n -2744: 17,\n 32: 18,\n 20480: 19}"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "dict(list(SEG_pipeline[\"sparse_category_encoder\"].vocabulary.items())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}