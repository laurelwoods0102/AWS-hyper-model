{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599741465860",
   "display_name": "Python 3.7.6 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp_api\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dill\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)  # Off when Distributed Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed, Dense, Conv1D, MaxPooling1D, Bidirectional, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG_CNNLSTM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200910-214530'"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., ..., 1., 3., 1.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "dataset = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.float32) #np.int64\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e405aa958bbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tuner.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtuner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtuner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, ignore, **kwds)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;34m\"\"\"unpickle an object from a file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\dill\\_dill.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#NOTE: if settings change, need to update attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStockUnpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_main_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__name__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ignore\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "with open(\"tuner.pkl\", \"rb\") as t:\n",
    "    tuner = dill.load(t)\n",
    "\n",
    "tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Parameters \n",
    "static_params = dict()\n",
    "\n",
    "static_params[\"PAST_HISTORY\"] = 16\n",
    "static_params[\"FUTURE_TARGET\"] = 8\n",
    "static_params[\"BATCH_SIZE\"] = 512\n",
    "static_params[\"EPOCHS\"] = 1000\n",
    "static_params[\"LOSS_FUNCTION\"] = 'sparse_categorical_crossentropy'\n",
    "static_params[\"VAL_SPLIT\"] = 0.2\n",
    "static_params[\"METRIC_ACCURACY\"] = 'accuracy'\n",
    "'''\n",
    "word_index = np.genfromtxt(\"data/word_index.csv\", delimiter=\"\\n\", dtype=np.int64)\n",
    "vocab_size = len(word_index)\n",
    "static_params[\"VOCAB_SIZE\"] = vocab_size\n",
    "'''\n",
    "static_params[\"VOCAB_SIZE\"] = 14482"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'\\nimport dill\\n\\nwith open(\"static/SparseCategoryEncoderDecoder.pkl\", \\'rb\\') as f:\\n    SparseCategoryEncoderDecoder = dill.load(f)\\n\\nstatic_params[\"VOCAB_SIZE\"] = SparseCategoryEncoderDecoder.vocab_size\\n\\nwith open(\"static/static_params.json\", \"w\") as j :\\n    json.dump(static_params, j, indent=4)\\n'"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "'''\n",
    "import dill\n",
    "\n",
    "with open(\"static/SparseCategoryEncoderDecoder.pkl\", 'rb') as f:\n",
    "    SparseCategoryEncoderDecoder = dill.load(f)\n",
    "\n",
    "static_params[\"VOCAB_SIZE\"] = SparseCategoryEncoderDecoder.vocab_size\n",
    "\n",
    "with open(\"static/static_params.json\", \"w\") as j :\n",
    "    json.dump(static_params, j, indent=4)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((14858, 16, 1), (14858, 8, 1))"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(dataset, 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().batch(static_params[\"BATCH_SIZE\"]).shuffle(static_params[\"BUFFER_SIZE\"]).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Conv1D(filters=32 , kernel_size=5, padding='causal', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Bidirectional(LSTM(232, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(168, return_sequences=True)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(TimeDistributed(Dense(static_params[\"VOCAB_SIZE\"], activation=\"softmax\")))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=1e-4),\n",
    "    loss=static_params[\"LOSS_FUNCTION\"],\n",
    "    metrics=[static_params[\"METRIC_ACCURACY\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/1000\n 1/24 [>.............................] - ETA: 0s - loss: nan - accuracy: 0.0000e+0 2/24 [=>............................] - ETA: 0s - loss: nan - accuracy: 0.012 3/24 [==>...........................] - ETA: 1s - loss: nan - accuracy: 0.019 4/24 [====>.........................] - ETA: 1s - loss: nan - accuracy: 0.022 5/24 [=====>........................] - ETA: 1s - loss: nan - accuracy: 0.024 6/24 [======>.......................] - ETA: 1s - loss: nan - accuracy: 0.026 7/24 [=======>......................] - ETA: 1s - loss: nan - accuracy: 0.026 8/24 [=========>....................] - ETA: 1s - loss: nan - accuracy: 0.028 9/24 [==========>...................] - ETA: 1s - loss: nan - accuracy: 0.02810/24 [===========>..................] - ETA: 1s - loss: nan - accuracy: 0.02911/24 [============>.................] - ETA: 0s - loss: nan - accuracy: 0.02912/24 [==============>...............] - ETA: 0s - loss: nan - accuracy: 0.02913/24 [===============>..............] - ETA: 0s - loss: nan - accuracy: 0.02914/24 [================>.............] - ETA: 0s - loss: nan - accuracy: 0.03015/24 [=================>............] - ETA: 0s - loss: nan - accuracy: 0.02916/24 [===================>..........] - ETA: 0s - loss: nan - accuracy: 0.02917/24 [====================>.........] - ETA: 0s - loss: nan - accuracy: 0.03018/24 [=====================>........] - ETA: 0s - loss: nan - accuracy: 0.03019/24 [======================>.......] - ETA: 0s - loss: nan - accuracy: 0.02920/24 [========================>.....] - ETA: 0s - loss: nan - accuracy: 0.02921/24 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.02922/24 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.02923/24 [===========================>..] - ETA: 0s - loss: nan - accuracy: 0.02924/24 [==============================] - ETA: 0s - loss: nan - accuracy: 0.02924/24 [==============================] - 3s 122ms/step - loss: nan - accuracy: 0.0297 - val_loss: 9.5807 - val_accuracy: 0.0000e+00\nEpoch 2/1000\n 1/24 [>.............................] - ETA: 0s - loss: nan - accuracy: 0.027 2/24 [=>............................] - ETA: 0s - loss: nan - accuracy: 0.028 3/24 [==>...........................] - ETA: 1s - loss: nan - accuracy: 0.029 4/24 [====>.........................] - ETA: 1s - loss: nan - accuracy: 0.027 5/24 [=====>........................] - ETA: 1s - loss: nan - accuracy: 0.028 6/24 [======>.......................] - ETA: 1s - loss: nan - accuracy: 0.028 7/24 [=======>......................] - ETA: 1s - loss: nan - accuracy: 0.028 8/24 [=========>....................] - ETA: 1s - loss: nan - accuracy: 0.028 9/24 [==========>...................] - ETA: 1s - loss: nan - accuracy: 0.02910/24 [===========>..................] - ETA: 1s - loss: nan - accuracy: 0.02911/24 [============>.................] - ETA: 0s - loss: nan - accuracy: 0.02912/24 [==============>...............] - ETA: 0s - loss: nan - accuracy: 0.02913/24 [===============>..............] - ETA: 0s - loss: nan - accuracy: 0.03014/24 [================>.............] - ETA: 0s - loss: nan - accuracy: 0.03015/24 [=================>............] - ETA: 0s - loss: nan - accuracy: 0.03016/24 [===================>..........] - ETA: 0s - loss: nan - accuracy: 0.03017/24 [====================>.........] - ETA: 0s - loss: nan - accuracy: 0.03018/24 [=====================>........] - ETA: 0s - loss: nan - accuracy: 0.03019/24 [======================>.......] - ETA: 0s - loss: nan - accuracy: 0.03120/24 [========================>.....] - ETA: 0s - loss: nan - accuracy: 0.03121/24 [=========================>....] - ETA: 0s - loss: nan - accuracy: 0.03122/24 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.03123/24 [===========================>..] - ETA: 0s - loss: nan - accuracy: 0.03124/24 [==============================] - 2s 84ms/step - loss: nan - accuracy: 0.0314 - val_loss: 9.5807 - val_accuracy: 0.0000e+00\n"
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, \n",
    "batch_size=static_params[\"BATCH_SIZE\"], validation_split=0.2, epochs=static_params[\"EPOCHS\"],\n",
    "callbacks=[keras.callbacks.EarlyStopping('val_accuracy')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}