{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599648197705",
   "display_name": "Python 3.7.6 64-bit ('ProgramData': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorboard.plugins.hparams import api as hp_api\n",
    "import kerastuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import dill\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)  # Off when Distributed Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"SEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'20200828-121953'"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0., 0., 0., ..., 1., 3., 1.], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "dataset = np.genfromtxt(\"data/{}_train_set.csv\".format(dataset_name), delimiter=\"\\n\", dtype=np.float32) #np.int64\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Parameters \n",
    "static_params = dict()\n",
    "\n",
    "static_params[\"PAST_HISTORY\"] = 16\n",
    "static_params[\"FUTURE_TARGET\"] = 8\n",
    "static_params[\"BATCH_SIZE\"] = 1024\n",
    "static_params[\"ACTIVATION\"] = 'softmax'\n",
    "static_params[\"LOSS_FUNCTION\"] = 'sparse_categorical_crossentropy'\n",
    "static_params[\"VAL_SPLIT\"] = 0.2\n",
    "static_params[\"METRIC_ACCURACY\"] = 'accuracy'\n",
    "static_params[\"OPTIMIZER\"] = 'adam'\n",
    "\n",
    "import dill\n",
    "\n",
    "with open(\"static/SparseCategoryEncoderDecoder.pkl\", 'rb') as f:\n",
    "    SparseCategoryEncoderDecoder = dill.load(f)\n",
    "\n",
    "static_params[\"VOCAB_SIZE\"] = SparseCategoryEncoderDecoder.vocab_size\n",
    "\n",
    "with open(\"static/static_params.json\", \"w\") as j :\n",
    "    json.dump(static_params, j, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'PAST_HISTORY': 16,\n 'FUTURE_TARGET': 8,\n 'BATCH_SIZE': 1024,\n 'ACTIVATION': 'softmax',\n 'LOSS_FUNCTION': 'sparse_categorical_crossentropy',\n 'VAL_SPLIT': 0.2,\n 'METRIC_ACCURACY': 'accuracy',\n 'OPTIMIZER': 'adam',\n 'VOCAB_SIZE': 14882}"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "with open(\"static/static_params.json\", \"r\") as j :\n",
    "    static_params = json.load(j)\n",
    "static_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(dataset, start_index, end_index, history_size, target_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        indices = range(i-history_size, i)\n",
    "        # Reshape data from (history_size,) to (history_size, n_feature)\n",
    "        data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
    "        #data.append(dataset[indices])\n",
    "        labels.append(np.reshape(dataset[i:i+target_size], (target_size, 1)))\n",
    "        #labels.append(dataset[i:i+target_size])\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((14858, 16, 1), (14858, 8, 1))"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "x_train, y_train = generate_timeseries(dataset, 0, None, static_params[\"PAST_HISTORY\"], static_params[\"FUTURE_TARGET\"])\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().batch(static_params[\"BATCH_SIZE\"]).shuffle(static_params[\"BUFFER_SIZE\"]).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorboard_callback(log_dir, hist_freq=1):\n",
    "    return keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=hist_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(hp.Int(\"layer_1_units\", min_value=32, max_value=256, step=8))))#step=30\n",
    "    model.add(keras.layers.Dropout(hp.Float(\"layer_1_dropout\", min_value=0.1, max_value=0.5, step=0.05)))\n",
    "    model.add(keras.layers.RepeatVector(static_params[\"FUTURE_TARGET\"]))\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(hp.Int(\"layer_2_units\", min_value=32, max_value=256, step=8), return_sequences=True)))\n",
    "    model.add(keras.layers.Dropout(hp.Float(\"layer_2_dropout\", min_value=0.1, max_value=0.5, step=0.05)))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Dense(static_params[\"VOCAB_SIZE\"], activation=static_params[\"ACTIVATION\"])))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss=static_params[\"LOSS_FUNCTION\"],\n",
    "        metrics=[static_params[\"METRIC_ACCURACY\"]]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
    }
   ],
   "source": [
    "tuner = kerastuner.tuners.Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=250,\n",
    "    factor=2,\n",
    "    hyperband_iterations=3,\n",
    "    distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    tune_new_entries=True,\n",
    "    directory=\"hyper_results\",\n",
    "    project_name=\"SEG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.0000e+00 - loss: 9.61  2/372 [..............................] - ETA: 9s - accuracy: 0.3711 - loss: 9.56  6/372 [..............................] - ETA: 6s - accuracy: 0.6413 - loss: 9.15 10/372 [..............................] - ETA: 6s - accuracy: 0.6926 - loss: 8.02 14/372 [>.............................] - ETA: 6s - accuracy: 0.7249 - loss: 6.63 18/372 [>.............................] - ETA: 5s - accuracy: 0.7368 - loss: 5.50 22/372 [>.............................] - ETA: 5s - accuracy: 0.7413 - loss: 4.79 26/372 [=>............................] - ETA: 5s - accuracy: 0.7518 - loss: 4.23 30/372 [=>............................] - ETA: 5s - accuracy: 0.7600 - loss: 3.82 34/372 [=>............................] - ETA: 5s - accuracy: 0.7647 - loss: 3.53 38/372 [==>...........................] - ETA: 4s - accuracy: 0.7694 - loss: 3.28 42/372 [==>...........................] - ETA: 4s - accuracy: 0.7736 - loss: 3.11 46/372 [==>...........................] - ETA: 4s - accuracy: 0.7773 - loss: 2.95 50/372 [===>..........................] - ETA: 4s - accuracy: 0.7799 - loss: 2.80 54/372 [===>..........................] - ETA: 4s - accuracy: 0.7821 - loss: 2.68 58/372 [===>..........................] - ETA: 4s - accuracy: 0.7827 - loss: 2.58 62/372 [====>.........................] - ETA: 4s - accuracy: 0.7838 - loss: 2.49 66/372 [====>.........................] - ETA: 4s - accuracy: 0.7840 - loss: 2.41 70/372 [====>.........................] - ETA: 4s - accuracy: 0.7836 - loss: 2.35 74/372 [====>.........................] - ETA: 4s - accuracy: 0.7823 - loss: 2.32 78/372 [=====>........................] - ETA: 4s - accuracy: 0.7833 - loss: 2.26 82/372 [=====>........................] - ETA: 4s - accuracy: 0.7829 - loss: 2.21 86/372 [=====>........................] - ETA: 3s - accuracy: 0.7847 - loss: 2.15 90/372 [======>.......................] - ETA: 3s - accuracy: 0.7859 - loss: 2.11 94/372 [======>.......................] - ETA: 3s - accuracy: 0.7875 - loss: 2.06 98/372 [======>.......................] - ETA: 3s - accuracy: 0.7849 - loss: 2.04102/372 [=======>......................] - ETA: 3s - accuracy: 0.7852 - loss: 2.00106/372 [=======>......................] - ETA: 3s - accuracy: 0.7859 - loss: 1.97110/372 [=======>......................] - ETA: 3s - accuracy: 0.7856 - loss: 1.94114/372 [========>.....................] - ETA: 3s - accuracy: 0.7854 - loss: 1.92118/372 [========>.....................] - ETA: 3s - accuracy: 0.7877 - loss: 1.88122/372 [========>.....................] - ETA: 3s - accuracy: 0.7874 - loss: 1.86126/372 [=========>....................] - ETA: 3s - accuracy: 0.7869 - loss: 1.84130/372 [=========>....................] - ETA: 3s - accuracy: 0.7870 - loss: 1.82134/372 [=========>....................] - ETA: 3s - accuracy: 0.7864 - loss: 1.80138/372 [==========>...................] - ETA: 3s - accuracy: 0.7874 - loss: 1.77142/372 [==========>...................] - ETA: 3s - accuracy: 0.7872 - loss: 1.76146/372 [==========>...................] - ETA: 3s - accuracy: 0.7872 - loss: 1.74150/372 [===========>..................] - ETA: 3s - accuracy: 0.7887 - loss: 1.71154/372 [===========>..................] - ETA: 2s - accuracy: 0.7882 - loss: 1.70158/372 [===========>..................] - ETA: 2s - accuracy: 0.7892 - loss: 1.68162/372 [============>.................] - ETA: 2s - accuracy: 0.7887 - loss: 1.66166/372 [============>.................] - ETA: 2s - accuracy: 0.7891 - loss: 1.64170/372 [============>.................] - ETA: 2s - accuracy: 0.7887 - loss: 1.63174/372 [=============>................] - ETA: 2s - accuracy: 0.7891 - loss: 1.61178/372 [=============>................] - ETA: 2s - accuracy: 0.7881 - loss: 1.61182/372 [=============>................] - ETA: 2s - accuracy: 0.7877 - loss: 1.60186/372 [==============>...............] - ETA: 2s - accuracy: 0.7881 - loss: 1.58190/372 [==============>...............] - ETA: 2s - accuracy: 0.7874 - loss: 1.57194/372 [==============>...............] - ETA: 2s - accuracy: 0.7880 - loss: 1.56198/372 [==============>...............] - ETA: 2s - accuracy: 0.7884 - loss: 1.55202/372 [===============>..............] - ETA: 2s - accuracy: 0.7890 - loss: 1.53206/372 [===============>..............] - ETA: 2s - accuracy: 0.7885 - loss: 1.53210/372 [===============>..............] - ETA: 2s - accuracy: 0.7892 - loss: 1.51214/372 [================>.............] - ETA: 2s - accuracy: 0.7897 - loss: 1.50218/372 [================>.............] - ETA: 2s - accuracy: 0.7890 - loss: 1.49222/372 [================>.............] - ETA: 2s - accuracy: 0.7887 - loss: 1.48226/372 [=================>............] - ETA: 1s - accuracy: 0.7889 - loss: 1.48230/372 [=================>............] - ETA: 1s - accuracy: 0.7888 - loss: 1.47234/372 [=================>............] - ETA: 1s - accuracy: 0.7891 - loss: 1.46238/372 [==================>...........] - ETA: 1s - accuracy: 0.7894 - loss: 1.45242/372 [==================>...........] - ETA: 1s - accuracy: 0.7888 - loss: 1.44246/372 [==================>...........] - ETA: 1s - accuracy: 0.7893 - loss: 1.44250/372 [===================>..........] - ETA: 1s - accuracy: 0.7888 - loss: 1.43254/372 [===================>..........] - ETA: 1s - accuracy: 0.7890 - loss: 1.42258/372 [===================>..........] - ETA: 1s - accuracy: 0.7893 - loss: 1.42262/372 [====================>.........] - ETA: 1s - accuracy: 0.7887 - loss: 1.41266/372 [====================>.........] - ETA: 1s - accuracy: 0.7886 - loss: 1.41270/372 [====================>.........] - ETA: 1s - accuracy: 0.7886 - loss: 1.40274/372 [=====================>........] - ETA: 1s - accuracy: 0.7890 - loss: 1.39278/372 [=====================>........] - ETA: 1s - accuracy: 0.7889 - loss: 1.39282/372 [=====================>........] - ETA: 1s - accuracy: 0.7884 - loss: 1.38286/372 [======================>.......] - ETA: 1s - accuracy: 0.7888 - loss: 1.38290/372 [======================>.......] - ETA: 1s - accuracy: 0.7890 - loss: 1.37294/372 [======================>.......] - ETA: 1s - accuracy: 0.7891 - loss: 1.37298/372 [=======================>......] - ETA: 0s - accuracy: 0.7902 - loss: 1.36302/372 [=======================>......] - ETA: 0s - accuracy: 0.7901 - loss: 1.35306/372 [=======================>......] - ETA: 0s - accuracy: 0.7902 - loss: 1.35310/372 [========================>.....] - ETA: 0s - accuracy: 0.7908 - loss: 1.34314/372 [========================>.....] - ETA: 0s - accuracy: 0.7915 - loss: 1.33318/372 [========================>.....] - ETA: 0s - accuracy: 0.7909 - loss: 1.33322/372 [========================>.....] - ETA: 0s - accuracy: 0.7909 - loss: 1.32326/372 [=========================>....] - ETA: 0s - accuracy: 0.7907 - loss: 1.31330/372 [=========================>....] - ETA: 0s - accuracy: 0.7908 - loss: 1.31334/372 [=========================>....] - ETA: 0s - accuracy: 0.7899 - loss: 1.31338/372 [==========================>...] - ETA: 0s - accuracy: 0.7895 - loss: 1.30342/372 [==========================>...] - ETA: 0s - accuracy: 0.7898 - loss: 1.29346/372 [==========================>...] - ETA: 0s - accuracy: 0.7897 - loss: 1.29350/372 [===========================>..] - ETA: 0s - accuracy: 0.7896 - loss: 1.29354/372 [===========================>..] - ETA: 0s - accuracy: 0.7896 - loss: 1.28358/372 [===========================>..] - ETA: 0s - accuracy: 0.7895 - loss: 1.28362/372 [============================>.] - ETA: 0s - accuracy: 0.7895 - loss: 1.27366/372 [============================>.] - ETA: 0s - accuracy: 0.7894 - loss: 1.26370/372 [============================>.] - ETA: 0s - accuracy: 0.7896 - loss: 1.26372/372 [==============================] - 8s 22ms/step - accuracy: 0.7895 - loss: 1.2592 - val_accuracy: 0.4256 - val_loss: 1.1576\nEpoch 2/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.6484 - loss: 0.91  5/372 [..............................] - ETA: 4s - accuracy: 0.7734 - loss: 0.82  9/372 [..............................] - ETA: 4s - accuracy: 0.7708 - loss: 0.80 13/372 [>.............................] - ETA: 4s - accuracy: 0.7755 - loss: 0.74 17/372 [>.............................] - ETA: 4s - accuracy: 0.7790 - loss: 0.75 21/372 [>.............................] - ETA: 4s - accuracy: 0.7891 - loss: 0.70 25/372 [=>............................] - ETA: 4s - accuracy: 0.7877 - loss: 0.72 29/372 [=>............................] - ETA: 4s - accuracy: 0.7939 - loss: 0.72 33/372 [=>............................] - ETA: 4s - accuracy: 0.7987 - loss: 0.71 37/372 [=>............................] - ETA: 4s - accuracy: 0.7969 - loss: 0.71 41/372 [==>...........................] - ETA: 4s - accuracy: 0.7933 - loss: 0.74 45/372 [==>...........................] - ETA: 4s - accuracy: 0.7928 - loss: 0.74 49/372 [==>...........................] - ETA: 4s - accuracy: 0.7951 - loss: 0.73 53/372 [===>..........................] - ETA: 4s - accuracy: 0.7919 - loss: 0.75 57/372 [===>..........................] - ETA: 4s - accuracy: 0.7914 - loss: 0.76 61/372 [===>..........................] - ETA: 4s - accuracy: 0.7941 - loss: 0.74 65/372 [====>.........................] - ETA: 4s - accuracy: 0.7927 - loss: 0.74 69/372 [====>.........................] - ETA: 4s - accuracy: 0.7940 - loss: 0.73 73/372 [====>.........................] - ETA: 3s - accuracy: 0.7952 - loss: 0.73 77/372 [=====>........................] - ETA: 3s - accuracy: 0.7942 - loss: 0.74 81/372 [=====>........................] - ETA: 3s - accuracy: 0.7938 - loss: 0.74 85/372 [=====>........................] - ETA: 3s - accuracy: 0.7928 - loss: 0.74 89/372 [======>.......................] - ETA: 3s - accuracy: 0.7918 - loss: 0.74 93/372 [======>.......................] - ETA: 3s - accuracy: 0.7912 - loss: 0.74 97/372 [======>.......................] - ETA: 3s - accuracy: 0.7920 - loss: 0.73101/372 [=======>......................] - ETA: 3s - accuracy: 0.7917 - loss: 0.74105/372 [=======>......................] - ETA: 3s - accuracy: 0.7908 - loss: 0.74109/372 [=======>......................] - ETA: 3s - accuracy: 0.7907 - loss: 0.74113/372 [========>.....................] - ETA: 3s - accuracy: 0.7912 - loss: 0.74117/372 [========>.....................] - ETA: 3s - accuracy: 0.7903 - loss: 0.74121/372 [========>.....................] - ETA: 3s - accuracy: 0.7895 - loss: 0.74125/372 [=========>....................] - ETA: 3s - accuracy: 0.7895 - loss: 0.74129/372 [=========>....................] - ETA: 3s - accuracy: 0.7880 - loss: 0.75133/372 [=========>....................] - ETA: 3s - accuracy: 0.7875 - loss: 0.76137/372 [==========>...................] - ETA: 3s - accuracy: 0.7870 - loss: 0.76141/372 [==========>...................] - ETA: 3s - accuracy: 0.7880 - loss: 0.76145/372 [==========>...................] - ETA: 3s - accuracy: 0.7886 - loss: 0.76149/372 [===========>..................] - ETA: 3s - accuracy: 0.7873 - loss: 0.76153/372 [===========>..................] - ETA: 2s - accuracy: 0.7868 - loss: 0.76157/372 [===========>..................] - ETA: 2s - accuracy: 0.7882 - loss: 0.76161/372 [===========>..................] - ETA: 2s - accuracy: 0.7886 - loss: 0.75165/372 [============>.................] - ETA: 2s - accuracy: 0.7869 - loss: 0.76169/372 [============>.................] - ETA: 2s - accuracy: 0.7870 - loss: 0.76173/372 [============>.................] - ETA: 2s - accuracy: 0.7875 - loss: 0.76177/372 [=============>................] - ETA: 2s - accuracy: 0.7866 - loss: 0.76181/372 [=============>................] - ETA: 2s - accuracy: 0.7863 - loss: 0.75185/372 [=============>................] - ETA: 2s - accuracy: 0.7867 - loss: 0.75189/372 [==============>...............] - ETA: 2s - accuracy: 0.7869 - loss: 0.75193/372 [==============>...............] - ETA: 2s - accuracy: 0.7872 - loss: 0.75197/372 [==============>...............] - ETA: 2s - accuracy: 0.7871 - loss: 0.75201/372 [===============>..............] - ETA: 2s - accuracy: 0.7874 - loss: 0.75205/372 [===============>..............] - ETA: 2s - accuracy: 0.7865 - loss: 0.76209/372 [===============>..............] - ETA: 2s - accuracy: 0.7856 - loss: 0.76213/372 [================>.............] - ETA: 2s - accuracy: 0.7856 - loss: 0.76217/372 [================>.............] - ETA: 2s - accuracy: 0.7859 - loss: 0.75221/372 [================>.............] - ETA: 2s - accuracy: 0.7860 - loss: 0.75225/372 [=================>............] - ETA: 1s - accuracy: 0.7852 - loss: 0.76229/372 [=================>............] - ETA: 1s - accuracy: 0.7853 - loss: 0.76233/372 [=================>............] - ETA: 1s - accuracy: 0.7856 - loss: 0.75237/372 [==================>...........] - ETA: 1s - accuracy: 0.7858 - loss: 0.76241/372 [==================>...........] - ETA: 1s - accuracy: 0.7864 - loss: 0.77245/372 [==================>...........] - ETA: 1s - accuracy: 0.7862 - loss: 0.77249/372 [===================>..........] - ETA: 1s - accuracy: 0.7864 - loss: 0.77253/372 [===================>..........] - ETA: 1s - accuracy: 0.7864 - loss: 0.78257/372 [===================>..........] - ETA: 1s - accuracy: 0.7866 - loss: 0.78261/372 [====================>.........] - ETA: 1s - accuracy: 0.7874 - loss: 0.78265/372 [====================>.........] - ETA: 1s - accuracy: 0.7871 - loss: 0.78269/372 [====================>.........] - ETA: 1s - accuracy: 0.7879 - loss: 0.79273/372 [=====================>........] - ETA: 1s - accuracy: 0.7883 - loss: 0.79277/372 [=====================>........] - ETA: 1s - accuracy: 0.7886 - loss: 0.79281/372 [=====================>........] - ETA: 1s - accuracy: 0.7886 - loss: 0.79285/372 [=====================>........] - ETA: 1s - accuracy: 0.7883 - loss: 0.79289/372 [======================>.......] - ETA: 1s - accuracy: 0.7882 - loss: 0.80293/372 [======================>.......] - ETA: 1s - accuracy: 0.7884 - loss: 0.80297/372 [======================>.......] - ETA: 1s - accuracy: 0.7890 - loss: 0.80301/372 [=======================>......] - ETA: 0s - accuracy: 0.7895 - loss: 0.80305/372 [=======================>......] - ETA: 0s - accuracy: 0.7896 - loss: 0.80309/372 [=======================>......] - ETA: 0s - accuracy: 0.7897 - loss: 0.80313/372 [========================>.....] - ETA: 0s - accuracy: 0.7900 - loss: 0.80317/372 [========================>.....] - ETA: 0s - accuracy: 0.7902 - loss: 0.80321/372 [========================>.....] - ETA: 0s - accuracy: 0.7898 - loss: 0.80325/372 [=========================>....] - ETA: 0s - accuracy: 0.7899 - loss: 0.80329/372 [=========================>....] - ETA: 0s - accuracy: 0.7899 - loss: 0.80333/372 [=========================>....] - ETA: 0s - accuracy: 0.7896 - loss: 0.80337/372 [==========================>...] - ETA: 0s - accuracy: 0.7901 - loss: 0.80341/372 [==========================>...] - ETA: 0s - accuracy: 0.7898 - loss: 0.80345/372 [==========================>...] - ETA: 0s - accuracy: 0.7895 - loss: 0.80349/372 [===========================>..] - ETA: 0s - accuracy: 0.7890 - loss: 0.80353/372 [===========================>..] - ETA: 0s - accuracy: 0.7895 - loss: 0.80357/372 [===========================>..] - ETA: 0s - accuracy: 0.7895 - loss: 0.80361/372 [============================>.] - ETA: 0s - accuracy: 0.7891 - loss: 0.80365/372 [============================>.] - ETA: 0s - accuracy: 0.7895 - loss: 0.80369/372 [============================>.] - ETA: 0s - accuracy: 0.7894 - loss: 0.80372/372 [==============================] - 6s 16ms/step - accuracy: 0.7891 - loss: 0.8026 - val_accuracy: 0.4256 - val_loss: 3.1069\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: a3609b15170527b4d97efa440720763e</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.42559725046157837</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_1_dropout: 0.15000000000000002</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_1_units: 240</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_2_dropout: 0.40000000000000013</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_2_units: 168</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/epochs: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.0000e+00 - loss: 9.61  2/372 [..............................] - ETA: 35s - accuracy: 0.0117 - loss: 9.593  6/372 [..............................] - ETA: 14s - accuracy: 0.4967 - loss: 9.497 10/372 [..............................] - ETA: 10s - accuracy: 0.6195 - loss: 9.303 14/372 [>.............................] - ETA: 8s - accuracy: 0.6546 - loss: 8.90 18/372 [>.............................] - ETA: 7s - accuracy: 0.6934 - loss: 8.26 22/372 [>.............................] - ETA: 7s - accuracy: 0.6999 - loss: 7.48 27/372 [=>............................] - ETA: 6s - accuracy: 0.7115 - loss: 6.47 31/372 [=>............................] - ETA: 6s - accuracy: 0.7261 - loss: 5.77 35/372 [=>............................] - ETA: 5s - accuracy: 0.7339 - loss: 5.25 40/372 [==>...........................] - ETA: 5s - accuracy: 0.7408 - loss: 4.74 45/372 [==>...........................] - ETA: 5s - accuracy: 0.7466 - loss: 4.33 50/372 [===>..........................] - ETA: 5s - accuracy: 0.7482 - loss: 4.04 55/372 [===>..........................] - ETA: 4s - accuracy: 0.7524 - loss: 3.79 59/372 [===>..........................] - ETA: 4s - accuracy: 0.7534 - loss: 3.63 63/372 [====>.........................] - ETA: 4s - accuracy: 0.7540 - loss: 3.50 68/372 [====>.........................] - ETA: 4s - accuracy: 0.7591 - loss: 3.31 73/372 [====>.........................] - ETA: 4s - accuracy: 0.7631 - loss: 3.17 78/372 [=====>........................] - ETA: 4s - accuracy: 0.7652 - loss: 3.03 83/372 [=====>........................] - ETA: 4s - accuracy: 0.7659 - loss: 2.93 87/372 [======>.......................] - ETA: 4s - accuracy: 0.7659 - loss: 2.86 91/372 [======>.......................] - ETA: 4s - accuracy: 0.7676 - loss: 2.78 95/372 [======>.......................] - ETA: 3s - accuracy: 0.7712 - loss: 2.71 99/372 [======>.......................] - ETA: 3s - accuracy: 0.7702 - loss: 2.66104/372 [=======>......................] - ETA: 3s - accuracy: 0.7717 - loss: 2.58108/372 [=======>......................] - ETA: 3s - accuracy: 0.7734 - loss: 2.52113/372 [========>.....................] - ETA: 3s - accuracy: 0.7749 - loss: 2.47117/372 [========>.....................] - ETA: 3s - accuracy: 0.7756 - loss: 2.42121/372 [========>.....................] - ETA: 3s - accuracy: 0.7769 - loss: 2.38125/372 [=========>....................] - ETA: 3s - accuracy: 0.7772 - loss: 2.34129/372 [=========>....................] - ETA: 3s - accuracy: 0.7787 - loss: 2.30133/372 [=========>....................] - ETA: 3s - accuracy: 0.7800 - loss: 2.26137/372 [==========>...................] - ETA: 3s - accuracy: 0.7816 - loss: 2.22141/372 [==========>...................] - ETA: 3s - accuracy: 0.7815 - loss: 2.19145/372 [==========>...................] - ETA: 3s - accuracy: 0.7819 - loss: 2.16149/372 [===========>..................] - ETA: 3s - accuracy: 0.7827 - loss: 2.12153/372 [===========>..................] - ETA: 3s - accuracy: 0.7826 - loss: 2.10157/372 [===========>..................] - ETA: 2s - accuracy: 0.7835 - loss: 2.07161/372 [===========>..................] - ETA: 2s - accuracy: 0.7822 - loss: 2.05166/372 [============>.................] - ETA: 2s - accuracy: 0.7829 - loss: 2.02170/372 [============>.................] - ETA: 2s - accuracy: 0.7835 - loss: 2.00174/372 [=============>................] - ETA: 2s - accuracy: 0.7832 - loss: 1.98179/372 [=============>................] - ETA: 2s - accuracy: 0.7829 - loss: 1.96184/372 [=============>................] - ETA: 2s - accuracy: 0.7829 - loss: 1.94189/372 [==============>...............] - ETA: 2s - accuracy: 0.7827 - loss: 1.92193/372 [==============>...............] - ETA: 2s - accuracy: 0.7829 - loss: 1.90197/372 [==============>...............] - ETA: 2s - accuracy: 0.7840 - loss: 1.88201/372 [===============>..............] - ETA: 2s - accuracy: 0.7840 - loss: 1.86205/372 [===============>..............] - ETA: 2s - accuracy: 0.7840 - loss: 1.85209/372 [===============>..............] - ETA: 2s - accuracy: 0.7845 - loss: 1.83214/372 [================>.............] - ETA: 2s - accuracy: 0.7855 - loss: 1.81219/372 [================>.............] - ETA: 2s - accuracy: 0.7854 - loss: 1.79224/372 [=================>............] - ETA: 1s - accuracy: 0.7862 - loss: 1.77229/372 [=================>............] - ETA: 1s - accuracy: 0.7864 - loss: 1.75233/372 [=================>............] - ETA: 1s - accuracy: 0.7866 - loss: 1.74237/372 [==================>...........] - ETA: 1s - accuracy: 0.7874 - loss: 1.73241/372 [==================>...........] - ETA: 1s - accuracy: 0.7873 - loss: 1.71246/372 [==================>...........] - ETA: 1s - accuracy: 0.7867 - loss: 1.70250/372 [===================>..........] - ETA: 1s - accuracy: 0.7870 - loss: 1.69254/372 [===================>..........] - ETA: 1s - accuracy: 0.7865 - loss: 1.68258/372 [===================>..........] - ETA: 1s - accuracy: 0.7864 - loss: 1.67263/372 [====================>.........] - ETA: 1s - accuracy: 0.7865 - loss: 1.66268/372 [====================>.........] - ETA: 1s - accuracy: 0.7862 - loss: 1.65272/372 [====================>.........] - ETA: 1s - accuracy: 0.7861 - loss: 1.64276/372 [=====================>........] - ETA: 1s - accuracy: 0.7866 - loss: 1.63281/372 [=====================>........] - ETA: 1s - accuracy: 0.7867 - loss: 1.61285/372 [=====================>........] - ETA: 1s - accuracy: 0.7871 - loss: 1.60289/372 [======================>.......] - ETA: 1s - accuracy: 0.7873 - loss: 1.59294/372 [======================>.......] - ETA: 1s - accuracy: 0.7875 - loss: 1.58299/372 [=======================>......] - ETA: 0s - accuracy: 0.7879 - loss: 1.57303/372 [=======================>......] - ETA: 0s - accuracy: 0.7872 - loss: 1.56307/372 [=======================>......] - ETA: 0s - accuracy: 0.7873 - loss: 1.55311/372 [========================>.....] - ETA: 0s - accuracy: 0.7870 - loss: 1.54315/372 [========================>.....] - ETA: 0s - accuracy: 0.7872 - loss: 1.53319/372 [========================>.....] - ETA: 0s - accuracy: 0.7873 - loss: 1.52323/372 [=========================>....] - ETA: 0s - accuracy: 0.7876 - loss: 1.51327/372 [=========================>....] - ETA: 0s - accuracy: 0.7880 - loss: 1.50331/372 [=========================>....] - ETA: 0s - accuracy: 0.7882 - loss: 1.49335/372 [==========================>...] - ETA: 0s - accuracy: 0.7879 - loss: 1.49339/372 [==========================>...] - ETA: 0s - accuracy: 0.7874 - loss: 1.48343/372 [==========================>...] - ETA: 0s - accuracy: 0.7875 - loss: 1.47348/372 [===========================>..] - ETA: 0s - accuracy: 0.7877 - loss: 1.46353/372 [===========================>..] - ETA: 0s - accuracy: 0.7872 - loss: 1.46358/372 [===========================>..] - ETA: 0s - accuracy: 0.7872 - loss: 1.45363/372 [============================>.] - ETA: 0s - accuracy: 0.7870 - loss: 1.44368/372 [============================>.] - ETA: 0s - accuracy: 0.7872 - loss: 1.43372/372 [==============================] - 8s 21ms/step - accuracy: 0.7870 - loss: 1.4344 - val_accuracy: 0.4256 - val_loss: 1.1878\nEpoch 2/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.7344 - loss: 0.99  6/372 [..............................] - ETA: 3s - accuracy: 0.7839 - loss: 0.82 11/372 [..............................] - ETA: 4s - accuracy: 0.7894 - loss: 0.82 16/372 [>.............................] - ETA: 4s - accuracy: 0.7844 - loss: 0.82 21/372 [>.............................] - ETA: 4s - accuracy: 0.7874 - loss: 0.79 26/372 [=>............................] - ETA: 4s - accuracy: 0.7867 - loss: 0.79 31/372 [=>............................] - ETA: 4s - accuracy: 0.7791 - loss: 0.77 36/372 [=>............................] - ETA: 3s - accuracy: 0.7728 - loss: 0.81 41/372 [==>...........................] - ETA: 3s - accuracy: 0.7745 - loss: 0.81 45/372 [==>...........................] - ETA: 3s - accuracy: 0.7770 - loss: 0.81 49/372 [==>...........................] - ETA: 3s - accuracy: 0.7785 - loss: 0.81 53/372 [===>..........................] - ETA: 3s - accuracy: 0.7795 - loss: 0.81 57/372 [===>..........................] - ETA: 3s - accuracy: 0.7813 - loss: 0.79 61/372 [===>..........................] - ETA: 3s - accuracy: 0.7814 - loss: 0.80 66/372 [====>.........................] - ETA: 3s - accuracy: 0.7846 - loss: 0.79 71/372 [====>.........................] - ETA: 3s - accuracy: 0.7858 - loss: 0.78 75/372 [=====>........................] - ETA: 3s - accuracy: 0.7852 - loss: 0.78 80/372 [=====>........................] - ETA: 3s - accuracy: 0.7869 - loss: 0.78 85/372 [=====>........................] - ETA: 3s - accuracy: 0.7847 - loss: 0.79 90/372 [======>.......................] - ETA: 3s - accuracy: 0.7839 - loss: 0.79 95/372 [======>.......................] - ETA: 3s - accuracy: 0.7828 - loss: 0.79 99/372 [======>.......................] - ETA: 3s - accuracy: 0.7827 - loss: 0.78103/372 [=======>......................] - ETA: 3s - accuracy: 0.7826 - loss: 0.78107/372 [=======>......................] - ETA: 3s - accuracy: 0.7829 - loss: 0.79111/372 [=======>......................] - ETA: 3s - accuracy: 0.7829 - loss: 0.78115/372 [========>.....................] - ETA: 3s - accuracy: 0.7839 - loss: 0.78119/372 [========>.....................] - ETA: 3s - accuracy: 0.7826 - loss: 0.78123/372 [========>.....................] - ETA: 3s - accuracy: 0.7822 - loss: 0.78127/372 [=========>....................] - ETA: 3s - accuracy: 0.7824 - loss: 0.78131/372 [=========>....................] - ETA: 3s - accuracy: 0.7826 - loss: 0.78136/372 [=========>....................] - ETA: 2s - accuracy: 0.7838 - loss: 0.78141/372 [==========>...................] - ETA: 2s - accuracy: 0.7833 - loss: 0.78146/372 [==========>...................] - ETA: 2s - accuracy: 0.7844 - loss: 0.78151/372 [===========>..................] - ETA: 2s - accuracy: 0.7829 - loss: 0.78155/372 [===========>..................] - ETA: 2s - accuracy: 0.7837 - loss: 0.77159/372 [===========>..................] - ETA: 2s - accuracy: 0.7836 - loss: 0.77163/372 [============>.................] - ETA: 2s - accuracy: 0.7840 - loss: 0.77168/372 [============>.................] - ETA: 2s - accuracy: 0.7848 - loss: 0.77173/372 [============>.................] - ETA: 2s - accuracy: 0.7836 - loss: 0.77177/372 [=============>................] - ETA: 2s - accuracy: 0.7846 - loss: 0.76181/372 [=============>................] - ETA: 2s - accuracy: 0.7841 - loss: 0.76186/372 [==============>...............] - ETA: 2s - accuracy: 0.7842 - loss: 0.76190/372 [==============>...............] - ETA: 2s - accuracy: 0.7841 - loss: 0.76194/372 [==============>...............] - ETA: 2s - accuracy: 0.7841 - loss: 0.76198/372 [==============>...............] - ETA: 2s - accuracy: 0.7834 - loss: 0.76202/372 [===============>..............] - ETA: 2s - accuracy: 0.7830 - loss: 0.76206/372 [===============>..............] - ETA: 2s - accuracy: 0.7835 - loss: 0.76210/372 [===============>..............] - ETA: 2s - accuracy: 0.7837 - loss: 0.76214/372 [================>.............] - ETA: 1s - accuracy: 0.7834 - loss: 0.76218/372 [================>.............] - ETA: 1s - accuracy: 0.7834 - loss: 0.75223/372 [================>.............] - ETA: 1s - accuracy: 0.7833 - loss: 0.75228/372 [=================>............] - ETA: 1s - accuracy: 0.7833 - loss: 0.75232/372 [=================>............] - ETA: 1s - accuracy: 0.7835 - loss: 0.75236/372 [==================>...........] - ETA: 1s - accuracy: 0.7836 - loss: 0.75241/372 [==================>...........] - ETA: 1s - accuracy: 0.7833 - loss: 0.75246/372 [==================>...........] - ETA: 1s - accuracy: 0.7829 - loss: 0.75251/372 [===================>..........] - ETA: 1s - accuracy: 0.7826 - loss: 0.75256/372 [===================>..........] - ETA: 1s - accuracy: 0.7823 - loss: 0.75260/372 [===================>..........] - ETA: 1s - accuracy: 0.7832 - loss: 0.75265/372 [====================>.........] - ETA: 1s - accuracy: 0.7833 - loss: 0.75270/372 [====================>.........] - ETA: 1s - accuracy: 0.7830 - loss: 0.75274/372 [=====================>........] - ETA: 1s - accuracy: 0.7829 - loss: 0.75278/372 [=====================>........] - ETA: 1s - accuracy: 0.7823 - loss: 0.75282/372 [=====================>........] - ETA: 1s - accuracy: 0.7821 - loss: 0.75286/372 [======================>.......] - ETA: 1s - accuracy: 0.7823 - loss: 0.75290/372 [======================>.......] - ETA: 1s - accuracy: 0.7827 - loss: 0.75294/372 [======================>.......] - ETA: 0s - accuracy: 0.7829 - loss: 0.74298/372 [=======================>......] - ETA: 0s - accuracy: 0.7827 - loss: 0.74302/372 [=======================>......] - ETA: 0s - accuracy: 0.7832 - loss: 0.74306/372 [=======================>......] - ETA: 0s - accuracy: 0.7831 - loss: 0.74310/372 [========================>.....] - ETA: 0s - accuracy: 0.7831 - loss: 0.74314/372 [========================>.....] - ETA: 0s - accuracy: 0.7829 - loss: 0.75318/372 [========================>.....] - ETA: 0s - accuracy: 0.7831 - loss: 0.75322/372 [========================>.....] - ETA: 0s - accuracy: 0.7830 - loss: 0.75327/372 [=========================>....] - ETA: 0s - accuracy: 0.7836 - loss: 0.74332/372 [=========================>....] - ETA: 0s - accuracy: 0.7833 - loss: 0.74336/372 [==========================>...] - ETA: 0s - accuracy: 0.7837 - loss: 0.74340/372 [==========================>...] - ETA: 0s - accuracy: 0.7837 - loss: 0.74344/372 [==========================>...] - ETA: 0s - accuracy: 0.7844 - loss: 0.74349/372 [===========================>..] - ETA: 0s - accuracy: 0.7844 - loss: 0.74354/372 [===========================>..] - ETA: 0s - accuracy: 0.7845 - loss: 0.74358/372 [===========================>..] - ETA: 0s - accuracy: 0.7851 - loss: 0.73362/372 [============================>.] - ETA: 0s - accuracy: 0.7852 - loss: 0.73366/372 [============================>.] - ETA: 0s - accuracy: 0.7849 - loss: 0.73370/372 [============================>.] - ETA: 0s - accuracy: 0.7848 - loss: 0.73372/372 [==============================] - 6s 15ms/step - accuracy: 0.7845 - loss: 0.7399 - val_accuracy: 0.4252 - val_loss: 1.1014\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 2c7fbb67b878bcdabd2891d68e3f0c8b</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.42559725046157837</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_1_dropout: 0.3500000000000001</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_1_units: 48</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_2_dropout: 0.40000000000000013</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_2_units: 120</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/epochs: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.0000e+00 - loss: 9.60  2/372 [..............................] - ETA: 36s - accuracy: 0.4004 - loss: 9.454  6/372 [..............................] - ETA: 15s - accuracy: 0.6549 - loss: 6.588 10/372 [..............................] - ETA: 10s - accuracy: 0.7133 - loss: 4.531 14/372 [>.............................] - ETA: 9s - accuracy: 0.7360 - loss: 3.64 18/372 [>.............................] - ETA: 8s - accuracy: 0.7493 - loss: 3.09 22/372 [>.............................] - ETA: 7s - accuracy: 0.7486 - loss: 2.86 26/372 [=>............................] - ETA: 6s - accuracy: 0.7590 - loss: 2.61 30/372 [=>............................] - ETA: 6s - accuracy: 0.7688 - loss: 2.40 34/372 [=>............................] - ETA: 6s - accuracy: 0.7734 - loss: 2.26 38/372 [==>...........................] - ETA: 5s - accuracy: 0.7732 - loss: 2.17 42/372 [==>...........................] - ETA: 5s - accuracy: 0.7719 - loss: 2.08 46/372 [==>...........................] - ETA: 5s - accuracy: 0.7773 - loss: 2.00 51/372 [===>..........................] - ETA: 5s - accuracy: 0.7769 - loss: 1.93 55/372 [===>..........................] - ETA: 5s - accuracy: 0.7793 - loss: 1.86 59/372 [===>..........................] - ETA: 5s - accuracy: 0.7777 - loss: 1.83 63/372 [====>.........................] - ETA: 4s - accuracy: 0.7777 - loss: 1.79 68/372 [====>.........................] - ETA: 4s - accuracy: 0.7760 - loss: 1.78 73/372 [====>.........................] - ETA: 4s - accuracy: 0.7760 - loss: 1.75 77/372 [=====>........................] - ETA: 4s - accuracy: 0.7787 - loss: 1.72 81/372 [=====>........................] - ETA: 4s - accuracy: 0.7792 - loss: 1.69 86/372 [=====>........................] - ETA: 4s - accuracy: 0.7807 - loss: 1.69 90/372 [======>.......................] - ETA: 4s - accuracy: 0.7793 - loss: 1.68 94/372 [======>.......................] - ETA: 4s - accuracy: 0.7803 - loss: 1.65 99/372 [======>.......................] - ETA: 3s - accuracy: 0.7818 - loss: 1.63103/372 [=======>......................] - ETA: 3s - accuracy: 0.7815 - loss: 1.62108/372 [=======>......................] - ETA: 3s - accuracy: 0.7812 - loss: 1.62113/372 [========>.....................] - ETA: 3s - accuracy: 0.7837 - loss: 1.59118/372 [========>.....................] - ETA: 3s - accuracy: 0.7838 - loss: 1.58122/372 [========>.....................] - ETA: 3s - accuracy: 0.7839 - loss: 1.57126/372 [=========>....................] - ETA: 3s - accuracy: 0.7842 - loss: 1.56130/372 [=========>....................] - ETA: 3s - accuracy: 0.7845 - loss: 1.55134/372 [=========>....................] - ETA: 3s - accuracy: 0.7846 - loss: 1.54138/372 [==========>...................] - ETA: 3s - accuracy: 0.7839 - loss: 1.54142/372 [==========>...................] - ETA: 3s - accuracy: 0.7841 - loss: 1.53146/372 [==========>...................] - ETA: 3s - accuracy: 0.7830 - loss: 1.52150/372 [===========>..................] - ETA: 3s - accuracy: 0.7843 - loss: 1.52154/372 [===========>..................] - ETA: 3s - accuracy: 0.7853 - loss: 1.51158/372 [===========>..................] - ETA: 2s - accuracy: 0.7858 - loss: 1.51162/372 [============>.................] - ETA: 2s - accuracy: 0.7868 - loss: 1.50166/372 [============>.................] - ETA: 2s - accuracy: 0.7862 - loss: 1.51170/372 [============>.................] - ETA: 2s - accuracy: 0.7854 - loss: 1.51175/372 [=============>................] - ETA: 2s - accuracy: 0.7861 - loss: 1.50180/372 [=============>................] - ETA: 2s - accuracy: 0.7868 - loss: 1.49185/372 [=============>................] - ETA: 2s - accuracy: 0.7861 - loss: 1.49189/372 [==============>...............] - ETA: 2s - accuracy: 0.7866 - loss: 1.49193/372 [==============>...............] - ETA: 2s - accuracy: 0.7857 - loss: 1.49197/372 [==============>...............] - ETA: 2s - accuracy: 0.7850 - loss: 1.49201/372 [===============>..............] - ETA: 2s - accuracy: 0.7860 - loss: 1.48205/372 [===============>..............] - ETA: 2s - accuracy: 0.7860 - loss: 1.48209/372 [===============>..............] - ETA: 2s - accuracy: 0.7867 - loss: 1.47213/372 [================>.............] - ETA: 2s - accuracy: 0.7857 - loss: 1.48217/372 [================>.............] - ETA: 2s - accuracy: 0.7862 - loss: 1.47221/372 [================>.............] - ETA: 2s - accuracy: 0.7857 - loss: 1.47225/372 [=================>............] - ETA: 2s - accuracy: 0.7863 - loss: 1.46230/372 [=================>............] - ETA: 1s - accuracy: 0.7868 - loss: 1.46234/372 [=================>............] - ETA: 1s - accuracy: 0.7865 - loss: 1.46238/372 [==================>...........] - ETA: 1s - accuracy: 0.7867 - loss: 1.46243/372 [==================>...........] - ETA: 1s - accuracy: 0.7872 - loss: 1.46248/372 [===================>..........] - ETA: 1s - accuracy: 0.7877 - loss: 1.46253/372 [===================>..........] - ETA: 1s - accuracy: 0.7883 - loss: 1.45258/372 [===================>..........] - ETA: 1s - accuracy: 0.7881 - loss: 1.45262/372 [====================>.........] - ETA: 1s - accuracy: 0.7879 - loss: 1.45266/372 [====================>.........] - ETA: 1s - accuracy: 0.7883 - loss: 1.45270/372 [====================>.........] - ETA: 1s - accuracy: 0.7886 - loss: 1.45274/372 [=====================>........] - ETA: 1s - accuracy: 0.7887 - loss: 1.44278/372 [=====================>........] - ETA: 1s - accuracy: 0.7899 - loss: 1.44282/372 [=====================>........] - ETA: 1s - accuracy: 0.7898 - loss: 1.43286/372 [======================>.......] - ETA: 1s - accuracy: 0.7898 - loss: 1.44290/372 [======================>.......] - ETA: 1s - accuracy: 0.7891 - loss: 1.44295/372 [======================>.......] - ETA: 1s - accuracy: 0.7891 - loss: 1.44300/372 [=======================>......] - ETA: 0s - accuracy: 0.7892 - loss: 1.43304/372 [=======================>......] - ETA: 0s - accuracy: 0.7887 - loss: 1.44308/372 [=======================>......] - ETA: 0s - accuracy: 0.7887 - loss: 1.44312/372 [========================>.....] - ETA: 0s - accuracy: 0.7891 - loss: 1.43316/372 [========================>.....] - ETA: 0s - accuracy: 0.7891 - loss: 1.43320/372 [========================>.....] - ETA: 0s - accuracy: 0.7893 - loss: 1.43324/372 [=========================>....] - ETA: 0s - accuracy: 0.7898 - loss: 1.42328/372 [=========================>....] - ETA: 0s - accuracy: 0.7898 - loss: 1.42333/372 [=========================>....] - ETA: 0s - accuracy: 0.7900 - loss: 1.42337/372 [==========================>...] - ETA: 0s - accuracy: 0.7898 - loss: 1.42341/372 [==========================>...] - ETA: 0s - accuracy: 0.7896 - loss: 1.42345/372 [==========================>...] - ETA: 0s - accuracy: 0.7898 - loss: 1.42349/372 [===========================>..] - ETA: 0s - accuracy: 0.7900 - loss: 1.42353/372 [===========================>..] - ETA: 0s - accuracy: 0.7896 - loss: 1.42357/372 [===========================>..] - ETA: 0s - accuracy: 0.7902 - loss: 1.41361/372 [============================>.] - ETA: 0s - accuracy: 0.7902 - loss: 1.42365/372 [============================>.] - ETA: 0s - accuracy: 0.7908 - loss: 1.41369/372 [============================>.] - ETA: 0s - accuracy: 0.7900 - loss: 1.42372/372 [==============================] - 8s 21ms/step - accuracy: 0.7901 - loss: 1.4215 - val_accuracy: 0.4256 - val_loss: 1.4726\nEpoch 2/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.8125 - loss: 1.71  6/372 [..............................] - ETA: 3s - accuracy: 0.7799 - loss: 1.44 11/372 [..............................] - ETA: 3s - accuracy: 0.7784 - loss: 1.55 16/372 [>.............................] - ETA: 4s - accuracy: 0.7700 - loss: 1.57 20/372 [>.............................] - ETA: 4s - accuracy: 0.7736 - loss: 1.53 25/372 [=>............................] - ETA: 3s - accuracy: 0.7758 - loss: 1.49 30/372 [=>............................] - ETA: 3s - accuracy: 0.7819 - loss: 1.45 34/372 [=>............................] - ETA: 3s - accuracy: 0.7846 - loss: 1.46 38/372 [==>...........................] - ETA: 4s - accuracy: 0.7870 - loss: 1.43 42/372 [==>...........................] - ETA: 3s - accuracy: 0.7858 - loss: 1.40 47/372 [==>...........................] - ETA: 3s - accuracy: 0.7878 - loss: 1.39 51/372 [===>..........................] - ETA: 3s - accuracy: 0.7878 - loss: 1.38 56/372 [===>..........................] - ETA: 3s - accuracy: 0.7931 - loss: 1.33 61/372 [===>..........................] - ETA: 3s - accuracy: 0.7912 - loss: 1.34 66/372 [====>.........................] - ETA: 3s - accuracy: 0.7915 - loss: 1.34 71/372 [====>.........................] - ETA: 3s - accuracy: 0.7921 - loss: 1.34 76/372 [=====>........................] - ETA: 3s - accuracy: 0.7899 - loss: 1.33 80/372 [=====>........................] - ETA: 3s - accuracy: 0.7896 - loss: 1.33 85/372 [=====>........................] - ETA: 3s - accuracy: 0.7916 - loss: 1.32 89/372 [======>.......................] - ETA: 3s - accuracy: 0.7909 - loss: 1.32 94/372 [======>.......................] - ETA: 3s - accuracy: 0.7918 - loss: 1.31 98/372 [======>.......................] - ETA: 3s - accuracy: 0.7891 - loss: 1.33102/372 [=======>......................] - ETA: 3s - accuracy: 0.7884 - loss: 1.33106/372 [=======>......................] - ETA: 3s - accuracy: 0.7878 - loss: 1.33110/372 [=======>......................] - ETA: 3s - accuracy: 0.7886 - loss: 1.33114/372 [========>.....................] - ETA: 3s - accuracy: 0.7896 - loss: 1.32118/372 [========>.....................] - ETA: 3s - accuracy: 0.7896 - loss: 1.33122/372 [========>.....................] - ETA: 3s - accuracy: 0.7909 - loss: 1.32126/372 [=========>....................] - ETA: 3s - accuracy: 0.7906 - loss: 1.32130/372 [=========>....................] - ETA: 3s - accuracy: 0.7908 - loss: 1.32134/372 [=========>....................] - ETA: 3s - accuracy: 0.7902 - loss: 1.32138/372 [==========>...................] - ETA: 2s - accuracy: 0.7898 - loss: 1.33142/372 [==========>...................] - ETA: 2s - accuracy: 0.7901 - loss: 1.32146/372 [==========>...................] - ETA: 2s - accuracy: 0.7907 - loss: 1.32150/372 [===========>..................] - ETA: 2s - accuracy: 0.7918 - loss: 1.31154/372 [===========>..................] - ETA: 2s - accuracy: 0.7914 - loss: 1.31158/372 [===========>..................] - ETA: 2s - accuracy: 0.7906 - loss: 1.31162/372 [============>.................] - ETA: 2s - accuracy: 0.7903 - loss: 1.31166/372 [============>.................] - ETA: 2s - accuracy: 0.7912 - loss: 1.30170/372 [============>.................] - ETA: 2s - accuracy: 0.7901 - loss: 1.31174/372 [=============>................] - ETA: 2s - accuracy: 0.7895 - loss: 1.31178/372 [=============>................] - ETA: 2s - accuracy: 0.7875 - loss: 1.31181/372 [=============>................] - ETA: 2s - accuracy: 0.7873 - loss: 1.32184/372 [=============>................] - ETA: 2s - accuracy: 0.7882 - loss: 1.31187/372 [==============>...............] - ETA: 2s - accuracy: 0.7880 - loss: 1.31190/372 [==============>...............] - ETA: 2s - accuracy: 0.7892 - loss: 1.30194/372 [==============>...............] - ETA: 2s - accuracy: 0.7894 - loss: 1.30198/372 [==============>...............] - ETA: 2s - accuracy: 0.7895 - loss: 1.29202/372 [===============>..............] - ETA: 2s - accuracy: 0.7908 - loss: 1.28206/372 [===============>..............] - ETA: 2s - accuracy: 0.7911 - loss: 1.27210/372 [===============>..............] - ETA: 2s - accuracy: 0.7912 - loss: 1.27215/372 [================>.............] - ETA: 2s - accuracy: 0.7921 - loss: 1.26220/372 [================>.............] - ETA: 2s - accuracy: 0.7919 - loss: 1.25225/372 [=================>............] - ETA: 1s - accuracy: 0.7922 - loss: 1.24229/372 [=================>............] - ETA: 1s - accuracy: 0.7920 - loss: 1.25234/372 [=================>............] - ETA: 1s - accuracy: 0.7927 - loss: 1.24238/372 [==================>...........] - ETA: 1s - accuracy: 0.7930 - loss: 1.24242/372 [==================>...........] - ETA: 1s - accuracy: 0.7930 - loss: 1.24246/372 [==================>...........] - ETA: 1s - accuracy: 0.7932 - loss: 1.23250/372 [===================>..........] - ETA: 1s - accuracy: 0.7928 - loss: 1.23254/372 [===================>..........] - ETA: 1s - accuracy: 0.7930 - loss: 1.23258/372 [===================>..........] - ETA: 1s - accuracy: 0.7932 - loss: 1.22262/372 [====================>.........] - ETA: 1s - accuracy: 0.7938 - loss: 1.22266/372 [====================>.........] - ETA: 1s - accuracy: 0.7938 - loss: 1.22270/372 [====================>.........] - ETA: 1s - accuracy: 0.7933 - loss: 1.22274/372 [=====================>........] - ETA: 1s - accuracy: 0.7925 - loss: 1.22278/372 [=====================>........] - ETA: 1s - accuracy: 0.7928 - loss: 1.22282/372 [=====================>........] - ETA: 1s - accuracy: 0.7928 - loss: 1.22286/372 [======================>.......] - ETA: 1s - accuracy: 0.7927 - loss: 1.22290/372 [======================>.......] - ETA: 1s - accuracy: 0.7925 - loss: 1.22294/372 [======================>.......] - ETA: 1s - accuracy: 0.7929 - loss: 1.22297/372 [======================>.......] - ETA: 1s - accuracy: 0.7925 - loss: 1.22301/372 [=======================>......] - ETA: 0s - accuracy: 0.7923 - loss: 1.21305/372 [=======================>......] - ETA: 0s - accuracy: 0.7922 - loss: 1.21309/372 [=======================>......] - ETA: 0s - accuracy: 0.7922 - loss: 1.21313/372 [========================>.....] - ETA: 0s - accuracy: 0.7924 - loss: 1.21317/372 [========================>.....] - ETA: 0s - accuracy: 0.7916 - loss: 1.21321/372 [========================>.....] - ETA: 0s - accuracy: 0.7917 - loss: 1.21325/372 [=========================>....] - ETA: 0s - accuracy: 0.7915 - loss: 1.21329/372 [=========================>....] - ETA: 0s - accuracy: 0.7916 - loss: 1.21333/372 [=========================>....] - ETA: 0s - accuracy: 0.7916 - loss: 1.21337/372 [==========================>...] - ETA: 0s - accuracy: 0.7917 - loss: 1.21341/372 [==========================>...] - ETA: 0s - accuracy: 0.7918 - loss: 1.21345/372 [==========================>...] - ETA: 0s - accuracy: 0.7916 - loss: 1.21349/372 [===========================>..] - ETA: 0s - accuracy: 0.7914 - loss: 1.20353/372 [===========================>..] - ETA: 0s - accuracy: 0.7912 - loss: 1.20357/372 [===========================>..] - ETA: 0s - accuracy: 0.7908 - loss: 1.21361/372 [============================>.] - ETA: 0s - accuracy: 0.7914 - loss: 1.20365/372 [============================>.] - ETA: 0s - accuracy: 0.7908 - loss: 1.21369/372 [============================>.] - ETA: 0s - accuracy: 0.7910 - loss: 1.20372/372 [==============================] - 6s 16ms/step - accuracy: 0.7905 - loss: 1.2069 - val_accuracy: 0.4256 - val_loss: 1.3111\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 1bc3b6d1514491dc1fad037c11afefa4</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.42559725046157837</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_1_dropout: 0.30000000000000004</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_1_units: 56</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_2_dropout: 0.25000000000000006</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_2_units: 80</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/epochs: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.0000e+00 - loss: 9.60  2/372 [..............................] - ETA: 36s - accuracy: 0.3711 - loss: 9.493  6/372 [..............................] - ETA: 15s - accuracy: 0.6478 - loss: 7.898 10/372 [..............................] - ETA: 10s - accuracy: 0.7039 - loss: 6.122 15/372 [>.............................] - ETA: 8s - accuracy: 0.7328 - loss: 4.61 20/372 [>.............................] - ETA: 7s - accuracy: 0.7316 - loss: 3.91 25/372 [=>............................] - ETA: 6s - accuracy: 0.7480 - loss: 3.36 30/372 [=>............................] - ETA: 6s - accuracy: 0.7516 - loss: 3.06 35/372 [=>............................] - ETA: 5s - accuracy: 0.7528 - loss: 2.82 40/372 [==>...........................] - ETA: 5s - accuracy: 0.7586 - loss: 2.62 44/372 [==>...........................] - ETA: 5s - accuracy: 0.7595 - loss: 2.50 49/372 [==>...........................] - ETA: 5s - accuracy: 0.7611 - loss: 2.42 54/372 [===>..........................] - ETA: 4s - accuracy: 0.7611 - loss: 2.32 58/372 [===>..........................] - ETA: 4s - accuracy: 0.7623 - loss: 2.25 62/372 [====>.........................] - ETA: 4s - accuracy: 0.7636 - loss: 2.19 66/372 [====>.........................] - ETA: 4s - accuracy: 0.7666 - loss: 2.13 71/372 [====>.........................] - ETA: 4s - accuracy: 0.7670 - loss: 2.08 76/372 [=====>........................] - ETA: 4s - accuracy: 0.7717 - loss: 2.01 81/372 [=====>........................] - ETA: 4s - accuracy: 0.7750 - loss: 1.95 85/372 [=====>........................] - ETA: 4s - accuracy: 0.7747 - loss: 1.93 90/372 [======>.......................] - ETA: 3s - accuracy: 0.7769 - loss: 1.88 95/372 [======>.......................] - ETA: 3s - accuracy: 0.7765 - loss: 1.84100/372 [=======>......................] - ETA: 3s - accuracy: 0.7803 - loss: 1.80104/372 [=======>......................] - ETA: 3s - accuracy: 0.7789 - loss: 1.79108/372 [=======>......................] - ETA: 3s - accuracy: 0.7800 - loss: 1.77112/372 [========>.....................] - ETA: 3s - accuracy: 0.7801 - loss: 1.75116/372 [========>.....................] - ETA: 3s - accuracy: 0.7807 - loss: 1.73120/372 [========>.....................] - ETA: 3s - accuracy: 0.7815 - loss: 1.71124/372 [=========>....................] - ETA: 3s - accuracy: 0.7817 - loss: 1.69128/372 [=========>....................] - ETA: 3s - accuracy: 0.7827 - loss: 1.68132/372 [=========>....................] - ETA: 3s - accuracy: 0.7838 - loss: 1.66137/372 [==========>...................] - ETA: 3s - accuracy: 0.7842 - loss: 1.65142/372 [==========>...................] - ETA: 3s - accuracy: 0.7833 - loss: 1.65147/372 [==========>...................] - ETA: 3s - accuracy: 0.7839 - loss: 1.63151/372 [===========>..................] - ETA: 3s - accuracy: 0.7839 - loss: 1.62156/372 [===========>..................] - ETA: 2s - accuracy: 0.7844 - loss: 1.61161/372 [===========>..................] - ETA: 2s - accuracy: 0.7842 - loss: 1.60166/372 [============>.................] - ETA: 2s - accuracy: 0.7845 - loss: 1.59170/372 [============>.................] - ETA: 2s - accuracy: 0.7848 - loss: 1.58174/372 [=============>................] - ETA: 2s - accuracy: 0.7851 - loss: 1.57179/372 [=============>................] - ETA: 2s - accuracy: 0.7858 - loss: 1.55184/372 [=============>................] - ETA: 2s - accuracy: 0.7865 - loss: 1.54188/372 [==============>...............] - ETA: 2s - accuracy: 0.7862 - loss: 1.54193/372 [==============>...............] - ETA: 2s - accuracy: 0.7868 - loss: 1.52198/372 [==============>...............] - ETA: 2s - accuracy: 0.7873 - loss: 1.52203/372 [===============>..............] - ETA: 2s - accuracy: 0.7862 - loss: 1.52208/372 [===============>..............] - ETA: 2s - accuracy: 0.7862 - loss: 1.52213/372 [================>.............] - ETA: 2s - accuracy: 0.7873 - loss: 1.50218/372 [================>.............] - ETA: 2s - accuracy: 0.7881 - loss: 1.49223/372 [================>.............] - ETA: 1s - accuracy: 0.7879 - loss: 1.49228/372 [=================>............] - ETA: 1s - accuracy: 0.7879 - loss: 1.48233/372 [=================>............] - ETA: 1s - accuracy: 0.7882 - loss: 1.48237/372 [==================>...........] - ETA: 1s - accuracy: 0.7889 - loss: 1.47241/372 [==================>...........] - ETA: 1s - accuracy: 0.7897 - loss: 1.46245/372 [==================>...........] - ETA: 1s - accuracy: 0.7895 - loss: 1.46249/372 [===================>..........] - ETA: 1s - accuracy: 0.7902 - loss: 1.45253/372 [===================>..........] - ETA: 1s - accuracy: 0.7908 - loss: 1.45257/372 [===================>..........] - ETA: 1s - accuracy: 0.7915 - loss: 1.44262/372 [====================>.........] - ETA: 1s - accuracy: 0.7915 - loss: 1.44266/372 [====================>.........] - ETA: 1s - accuracy: 0.7912 - loss: 1.44271/372 [====================>.........] - ETA: 1s - accuracy: 0.7911 - loss: 1.43275/372 [=====================>........] - ETA: 1s - accuracy: 0.7914 - loss: 1.43279/372 [=====================>........] - ETA: 1s - accuracy: 0.7919 - loss: 1.42283/372 [=====================>........] - ETA: 1s - accuracy: 0.7919 - loss: 1.41287/372 [======================>.......] - ETA: 1s - accuracy: 0.7922 - loss: 1.41291/372 [======================>.......] - ETA: 1s - accuracy: 0.7927 - loss: 1.41295/372 [======================>.......] - ETA: 1s - accuracy: 0.7922 - loss: 1.41299/372 [=======================>......] - ETA: 0s - accuracy: 0.7927 - loss: 1.40303/372 [=======================>......] - ETA: 0s - accuracy: 0.7929 - loss: 1.39307/372 [=======================>......] - ETA: 0s - accuracy: 0.7926 - loss: 1.39311/372 [========================>.....] - ETA: 0s - accuracy: 0.7921 - loss: 1.39315/372 [========================>.....] - ETA: 0s - accuracy: 0.7919 - loss: 1.40319/372 [========================>.....] - ETA: 0s - accuracy: 0.7918 - loss: 1.40323/372 [=========================>....] - ETA: 0s - accuracy: 0.7917 - loss: 1.39327/372 [=========================>....] - ETA: 0s - accuracy: 0.7918 - loss: 1.40331/372 [=========================>....] - ETA: 0s - accuracy: 0.7917 - loss: 1.40335/372 [==========================>...] - ETA: 0s - accuracy: 0.7922 - loss: 1.39339/372 [==========================>...] - ETA: 0s - accuracy: 0.7920 - loss: 1.39343/372 [==========================>...] - ETA: 0s - accuracy: 0.7918 - loss: 1.39347/372 [==========================>...] - ETA: 0s - accuracy: 0.7918 - loss: 1.39351/372 [===========================>..] - ETA: 0s - accuracy: 0.7915 - loss: 1.39355/372 [===========================>..] - ETA: 0s - accuracy: 0.7914 - loss: 1.38359/372 [===========================>..] - ETA: 0s - accuracy: 0.7912 - loss: 1.38363/372 [============================>.] - ETA: 0s - accuracy: 0.7915 - loss: 1.38367/372 [============================>.] - ETA: 0s - accuracy: 0.7908 - loss: 1.38371/372 [============================>.] - ETA: 0s - accuracy: 0.7904 - loss: 1.38372/372 [==============================] - 8s 21ms/step - accuracy: 0.7904 - loss: 1.3815 - val_accuracy: 0.4256 - val_loss: 1.4044\nEpoch 2/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.7969 - loss: 1.12  5/372 [..............................] - ETA: 4s - accuracy: 0.8125 - loss: 0.94  9/372 [..............................] - ETA: 4s - accuracy: 0.7782 - loss: 1.03 14/372 [>.............................] - ETA: 4s - accuracy: 0.7866 - loss: 1.02 19/372 [>.............................] - ETA: 4s - accuracy: 0.7905 - loss: 1.00 24/372 [>.............................] - ETA: 4s - accuracy: 0.7918 - loss: 1.03 29/372 [=>............................] - ETA: 4s - accuracy: 0.7953 - loss: 1.01 34/372 [=>............................] - ETA: 4s - accuracy: 0.7923 - loss: 1.03 39/372 [==>...........................] - ETA: 3s - accuracy: 0.7859 - loss: 1.07 43/372 [==>...........................] - ETA: 3s - accuracy: 0.7862 - loss: 1.05 47/372 [==>...........................] - ETA: 3s - accuracy: 0.7884 - loss: 1.03 52/372 [===>..........................] - ETA: 3s - accuracy: 0.7921 - loss: 1.01 56/372 [===>..........................] - ETA: 3s - accuracy: 0.7952 - loss: 0.99 61/372 [===>..........................] - ETA: 3s - accuracy: 0.7940 - loss: 1.03 65/372 [====>.........................] - ETA: 3s - accuracy: 0.7932 - loss: 1.06 70/372 [====>.........................] - ETA: 3s - accuracy: 0.7920 - loss: 1.07 74/372 [====>.........................] - ETA: 3s - accuracy: 0.7914 - loss: 1.07 78/372 [=====>........................] - ETA: 3s - accuracy: 0.7905 - loss: 1.07 82/372 [=====>........................] - ETA: 3s - accuracy: 0.7893 - loss: 1.08 86/372 [=====>........................] - ETA: 3s - accuracy: 0.7904 - loss: 1.07 90/372 [======>.......................] - ETA: 3s - accuracy: 0.7907 - loss: 1.06 94/372 [======>.......................] - ETA: 3s - accuracy: 0.7909 - loss: 1.05 98/372 [======>.......................] - ETA: 3s - accuracy: 0.7906 - loss: 1.04102/372 [=======>......................] - ETA: 3s - accuracy: 0.7910 - loss: 1.03106/372 [=======>......................] - ETA: 3s - accuracy: 0.7901 - loss: 1.02110/372 [=======>......................] - ETA: 3s - accuracy: 0.7918 - loss: 1.00114/372 [========>.....................] - ETA: 3s - accuracy: 0.7905 - loss: 0.99118/372 [========>.....................] - ETA: 3s - accuracy: 0.7920 - loss: 0.98122/372 [========>.....................] - ETA: 3s - accuracy: 0.7918 - loss: 0.98126/372 [=========>....................] - ETA: 3s - accuracy: 0.7922 - loss: 0.98131/372 [=========>....................] - ETA: 3s - accuracy: 0.7920 - loss: 0.97135/372 [=========>....................] - ETA: 3s - accuracy: 0.7911 - loss: 0.97140/372 [==========>...................] - ETA: 2s - accuracy: 0.7920 - loss: 0.97144/372 [==========>...................] - ETA: 2s - accuracy: 0.7929 - loss: 0.96149/372 [===========>..................] - ETA: 2s - accuracy: 0.7930 - loss: 0.95153/372 [===========>..................] - ETA: 2s - accuracy: 0.7922 - loss: 0.95157/372 [===========>..................] - ETA: 2s - accuracy: 0.7919 - loss: 0.94161/372 [===========>..................] - ETA: 2s - accuracy: 0.7907 - loss: 0.95165/372 [============>.................] - ETA: 2s - accuracy: 0.7908 - loss: 0.94169/372 [============>.................] - ETA: 2s - accuracy: 0.7899 - loss: 0.94173/372 [============>.................] - ETA: 2s - accuracy: 0.7906 - loss: 0.93177/372 [=============>................] - ETA: 2s - accuracy: 0.7902 - loss: 0.93182/372 [=============>................] - ETA: 2s - accuracy: 0.7890 - loss: 0.93186/372 [==============>...............] - ETA: 2s - accuracy: 0.7882 - loss: 0.93190/372 [==============>...............] - ETA: 2s - accuracy: 0.7880 - loss: 0.93194/372 [==============>...............] - ETA: 2s - accuracy: 0.7883 - loss: 0.92199/372 [===============>..............] - ETA: 2s - accuracy: 0.7879 - loss: 0.92204/372 [===============>..............] - ETA: 2s - accuracy: 0.7872 - loss: 0.92209/372 [===============>..............] - ETA: 2s - accuracy: 0.7878 - loss: 0.91214/372 [================>.............] - ETA: 2s - accuracy: 0.7866 - loss: 0.91219/372 [================>.............] - ETA: 1s - accuracy: 0.7868 - loss: 0.91224/372 [=================>............] - ETA: 1s - accuracy: 0.7863 - loss: 0.91229/372 [=================>............] - ETA: 1s - accuracy: 0.7861 - loss: 0.91233/372 [=================>............] - ETA: 1s - accuracy: 0.7867 - loss: 0.90237/372 [==================>...........] - ETA: 1s - accuracy: 0.7869 - loss: 0.90241/372 [==================>...........] - ETA: 1s - accuracy: 0.7874 - loss: 0.90245/372 [==================>...........] - ETA: 1s - accuracy: 0.7867 - loss: 0.90249/372 [===================>..........] - ETA: 1s - accuracy: 0.7868 - loss: 0.89253/372 [===================>..........] - ETA: 1s - accuracy: 0.7876 - loss: 0.89257/372 [===================>..........] - ETA: 1s - accuracy: 0.7872 - loss: 0.89261/372 [====================>.........] - ETA: 1s - accuracy: 0.7881 - loss: 0.88266/372 [====================>.........] - ETA: 1s - accuracy: 0.7877 - loss: 0.88271/372 [====================>.........] - ETA: 1s - accuracy: 0.7872 - loss: 0.88276/372 [=====================>........] - ETA: 1s - accuracy: 0.7868 - loss: 0.88281/372 [=====================>........] - ETA: 1s - accuracy: 0.7868 - loss: 0.88285/372 [=====================>........] - ETA: 1s - accuracy: 0.7870 - loss: 0.88289/372 [======================>.......] - ETA: 1s - accuracy: 0.7874 - loss: 0.87293/372 [======================>.......] - ETA: 1s - accuracy: 0.7878 - loss: 0.87297/372 [======================>.......] - ETA: 0s - accuracy: 0.7876 - loss: 0.87301/372 [=======================>......] - ETA: 0s - accuracy: 0.7870 - loss: 0.87305/372 [=======================>......] - ETA: 0s - accuracy: 0.7873 - loss: 0.87309/372 [=======================>......] - ETA: 0s - accuracy: 0.7870 - loss: 0.87313/372 [========================>.....] - ETA: 0s - accuracy: 0.7872 - loss: 0.86317/372 [========================>.....] - ETA: 0s - accuracy: 0.7871 - loss: 0.86322/372 [========================>.....] - ETA: 0s - accuracy: 0.7867 - loss: 0.86327/372 [=========================>....] - ETA: 0s - accuracy: 0.7866 - loss: 0.86332/372 [=========================>....] - ETA: 0s - accuracy: 0.7867 - loss: 0.86336/372 [==========================>...] - ETA: 0s - accuracy: 0.7864 - loss: 0.86341/372 [==========================>...] - ETA: 0s - accuracy: 0.7862 - loss: 0.86346/372 [==========================>...] - ETA: 0s - accuracy: 0.7857 - loss: 0.86350/372 [===========================>..] - ETA: 0s - accuracy: 0.7857 - loss: 0.86355/372 [===========================>..] - ETA: 0s - accuracy: 0.7859 - loss: 0.86360/372 [============================>.] - ETA: 0s - accuracy: 0.7859 - loss: 0.86365/372 [============================>.] - ETA: 0s - accuracy: 0.7855 - loss: 0.86370/372 [============================>.] - ETA: 0s - accuracy: 0.7858 - loss: 0.85372/372 [==============================] - 5s 15ms/step - accuracy: 0.7860 - loss: 0.8583 - val_accuracy: 0.4256 - val_loss: 1.0827\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 5824094184e1be7fc7f305c4c6b6c721</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.42559725046157837</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_1_dropout: 0.15000000000000002</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_1_units: 152</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_2_dropout: 0.30000000000000004</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_2_units: 40</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/epochs: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.0000e+00 - loss: 9.61  2/372 [..............................] - ETA: 37s - accuracy: 0.3359 - loss: 9.591  7/372 [..............................] - ETA: 13s - accuracy: 0.6395 - loss: 9.397 11/372 [..............................] - ETA: 10s - accuracy: 0.6928 - loss: 8.976 15/372 [>.............................] - ETA: 8s - accuracy: 0.7258 - loss: 8.43 19/372 [>.............................] - ETA: 7s - accuracy: 0.7416 - loss: 7.88 23/372 [>.............................] - ETA: 7s - accuracy: 0.7500 - loss: 7.35 27/372 [=>............................] - ETA: 6s - accuracy: 0.7584 - loss: 6.79 31/372 [=>............................] - ETA: 6s - accuracy: 0.7637 - loss: 6.28 36/372 [=>............................] - ETA: 5s - accuracy: 0.7667 - loss: 5.70 41/372 [==>...........................] - ETA: 5s - accuracy: 0.7752 - loss: 5.18 45/372 [==>...........................] - ETA: 5s - accuracy: 0.7766 - loss: 4.84 50/372 [===>..........................] - ETA: 5s - accuracy: 0.7804 - loss: 4.47 55/372 [===>..........................] - ETA: 4s - accuracy: 0.7823 - loss: 4.17 60/372 [===>..........................] - ETA: 4s - accuracy: 0.7818 - loss: 3.91 65/372 [====>.........................] - ETA: 4s - accuracy: 0.7799 - loss: 3.72 70/372 [====>.........................] - ETA: 4s - accuracy: 0.7796 - loss: 3.55 75/372 [=====>........................] - ETA: 4s - accuracy: 0.7819 - loss: 3.38 80/372 [=====>........................] - ETA: 4s - accuracy: 0.7838 - loss: 3.23 85/372 [=====>........................] - ETA: 4s - accuracy: 0.7815 - loss: 3.13 90/372 [======>.......................] - ETA: 4s - accuracy: 0.7777 - loss: 3.04 95/372 [======>.......................] - ETA: 3s - accuracy: 0.7800 - loss: 2.93100/372 [=======>......................] - ETA: 3s - accuracy: 0.7798 - loss: 2.84104/372 [=======>......................] - ETA: 3s - accuracy: 0.7814 - loss: 2.78108/372 [=======>......................] - ETA: 3s - accuracy: 0.7835 - loss: 2.71112/372 [========>.....................] - ETA: 3s - accuracy: 0.7829 - loss: 2.66117/372 [========>.....................] - ETA: 3s - accuracy: 0.7831 - loss: 2.59121/372 [========>.....................] - ETA: 3s - accuracy: 0.7829 - loss: 2.54125/372 [=========>....................] - ETA: 3s - accuracy: 0.7835 - loss: 2.49129/372 [=========>....................] - ETA: 3s - accuracy: 0.7842 - loss: 2.45133/372 [=========>....................] - ETA: 3s - accuracy: 0.7845 - loss: 2.41137/372 [==========>...................] - ETA: 3s - accuracy: 0.7845 - loss: 2.38141/372 [==========>...................] - ETA: 3s - accuracy: 0.7840 - loss: 2.34145/372 [==========>...................] - ETA: 3s - accuracy: 0.7847 - loss: 2.31149/372 [===========>..................] - ETA: 3s - accuracy: 0.7857 - loss: 2.27153/372 [===========>..................] - ETA: 3s - accuracy: 0.7864 - loss: 2.24157/372 [===========>..................] - ETA: 2s - accuracy: 0.7861 - loss: 2.21161/372 [===========>..................] - ETA: 2s - accuracy: 0.7867 - loss: 2.17166/372 [============>.................] - ETA: 2s - accuracy: 0.7862 - loss: 2.14170/372 [============>.................] - ETA: 2s - accuracy: 0.7864 - loss: 2.12174/372 [=============>................] - ETA: 2s - accuracy: 0.7857 - loss: 2.09178/372 [=============>................] - ETA: 2s - accuracy: 0.7855 - loss: 2.07182/372 [=============>................] - ETA: 2s - accuracy: 0.7855 - loss: 2.05186/372 [==============>...............] - ETA: 2s - accuracy: 0.7864 - loss: 2.02190/372 [==============>...............] - ETA: 2s - accuracy: 0.7858 - loss: 2.00195/372 [==============>...............] - ETA: 2s - accuracy: 0.7875 - loss: 1.97199/372 [===============>..............] - ETA: 2s - accuracy: 0.7881 - loss: 1.95204/372 [===============>..............] - ETA: 2s - accuracy: 0.7872 - loss: 1.93209/372 [===============>..............] - ETA: 2s - accuracy: 0.7867 - loss: 1.92214/372 [================>.............] - ETA: 2s - accuracy: 0.7863 - loss: 1.90219/372 [================>.............] - ETA: 2s - accuracy: 0.7864 - loss: 1.88223/372 [================>.............] - ETA: 2s - accuracy: 0.7858 - loss: 1.86228/372 [=================>............] - ETA: 1s - accuracy: 0.7862 - loss: 1.84232/372 [=================>............] - ETA: 1s - accuracy: 0.7862 - loss: 1.83236/372 [==================>...........] - ETA: 1s - accuracy: 0.7864 - loss: 1.81240/372 [==================>...........] - ETA: 1s - accuracy: 0.7873 - loss: 1.80244/372 [==================>...........] - ETA: 1s - accuracy: 0.7880 - loss: 1.78248/372 [===================>..........] - ETA: 1s - accuracy: 0.7887 - loss: 1.77252/372 [===================>..........] - ETA: 1s - accuracy: 0.7886 - loss: 1.75256/372 [===================>..........] - ETA: 1s - accuracy: 0.7888 - loss: 1.74260/372 [===================>..........] - ETA: 1s - accuracy: 0.7886 - loss: 1.73265/372 [====================>.........] - ETA: 1s - accuracy: 0.7889 - loss: 1.71269/372 [====================>.........] - ETA: 1s - accuracy: 0.7889 - loss: 1.70274/372 [=====================>........] - ETA: 1s - accuracy: 0.7894 - loss: 1.69279/372 [=====================>........] - ETA: 1s - accuracy: 0.7894 - loss: 1.68283/372 [=====================>........] - ETA: 1s - accuracy: 0.7894 - loss: 1.67287/372 [======================>.......] - ETA: 1s - accuracy: 0.7897 - loss: 1.66291/372 [======================>.......] - ETA: 1s - accuracy: 0.7898 - loss: 1.65296/372 [======================>.......] - ETA: 1s - accuracy: 0.7896 - loss: 1.64301/372 [=======================>......] - ETA: 0s - accuracy: 0.7899 - loss: 1.63306/372 [=======================>......] - ETA: 0s - accuracy: 0.7897 - loss: 1.61310/372 [========================>.....] - ETA: 0s - accuracy: 0.7904 - loss: 1.60314/372 [========================>.....] - ETA: 0s - accuracy: 0.7902 - loss: 1.60318/372 [========================>.....] - ETA: 0s - accuracy: 0.7901 - loss: 1.59322/372 [========================>.....] - ETA: 0s - accuracy: 0.7907 - loss: 1.58326/372 [=========================>....] - ETA: 0s - accuracy: 0.7907 - loss: 1.57330/372 [=========================>....] - ETA: 0s - accuracy: 0.7909 - loss: 1.57334/372 [=========================>....] - ETA: 0s - accuracy: 0.7909 - loss: 1.56338/372 [==========================>...] - ETA: 0s - accuracy: 0.7905 - loss: 1.55342/372 [==========================>...] - ETA: 0s - accuracy: 0.7910 - loss: 1.54346/372 [==========================>...] - ETA: 0s - accuracy: 0.7912 - loss: 1.54350/372 [===========================>..] - ETA: 0s - accuracy: 0.7910 - loss: 1.53355/372 [===========================>..] - ETA: 0s - accuracy: 0.7902 - loss: 1.52359/372 [===========================>..] - ETA: 0s - accuracy: 0.7902 - loss: 1.52363/372 [============================>.] - ETA: 0s - accuracy: 0.7900 - loss: 1.51367/372 [============================>.] - ETA: 0s - accuracy: 0.7899 - loss: 1.51372/372 [==============================] - ETA: 0s - accuracy: 0.7897 - loss: 1.50372/372 [==============================] - 8s 21ms/step - accuracy: 0.7897 - loss: 1.5069 - val_accuracy: 0.4256 - val_loss: 1.5702\nEpoch 2/2\n  1/372 [..............................] - ETA: 0s - accuracy: 0.8672 - loss: 0.61  6/372 [..............................] - ETA: 3s - accuracy: 0.8034 - loss: 0.92 11/372 [..............................] - ETA: 3s - accuracy: 0.7855 - loss: 0.96 16/372 [>.............................] - ETA: 3s - accuracy: 0.7915 - loss: 0.95 21/372 [>.............................] - ETA: 4s - accuracy: 0.7926 - loss: 0.95 26/372 [=>............................] - ETA: 3s - accuracy: 0.7928 - loss: 0.95 30/372 [=>............................] - ETA: 4s - accuracy: 0.7940 - loss: 0.94 35/372 [=>............................] - ETA: 3s - accuracy: 0.7988 - loss: 0.93 40/372 [==>...........................] - ETA: 3s - accuracy: 0.7971 - loss: 0.94 45/372 [==>...........................] - ETA: 3s - accuracy: 0.7937 - loss: 0.95 49/372 [==>...........................] - ETA: 3s - accuracy: 0.7927 - loss: 0.95 53/372 [===>..........................] - ETA: 3s - accuracy: 0.7937 - loss: 0.94 57/372 [===>..........................] - ETA: 3s - accuracy: 0.7916 - loss: 0.96 61/372 [===>..........................] - ETA: 3s - accuracy: 0.7907 - loss: 0.96 65/372 [====>.........................] - ETA: 3s - accuracy: 0.7919 - loss: 0.95 70/372 [====>.........................] - ETA: 3s - accuracy: 0.7926 - loss: 0.94 74/372 [====>.........................] - ETA: 3s - accuracy: 0.7945 - loss: 0.94 79/372 [=====>........................] - ETA: 3s - accuracy: 0.7944 - loss: 0.94 84/372 [=====>........................] - ETA: 3s - accuracy: 0.7942 - loss: 0.94 88/372 [======>.......................] - ETA: 3s - accuracy: 0.7950 - loss: 0.94 92/372 [======>.......................] - ETA: 3s - accuracy: 0.7950 - loss: 0.94 96/372 [======>.......................] - ETA: 3s - accuracy: 0.7959 - loss: 0.94100/372 [=======>......................] - ETA: 3s - accuracy: 0.7941 - loss: 0.94104/372 [=======>......................] - ETA: 3s - accuracy: 0.7932 - loss: 0.95108/372 [=======>......................] - ETA: 3s - accuracy: 0.7940 - loss: 0.94112/372 [========>.....................] - ETA: 3s - accuracy: 0.7943 - loss: 0.94116/372 [========>.....................] - ETA: 3s - accuracy: 0.7944 - loss: 0.94120/372 [========>.....................] - ETA: 3s - accuracy: 0.7940 - loss: 0.94124/372 [=========>....................] - ETA: 3s - accuracy: 0.7933 - loss: 0.94128/372 [=========>....................] - ETA: 3s - accuracy: 0.7935 - loss: 0.95132/372 [=========>....................] - ETA: 3s - accuracy: 0.7945 - loss: 0.94136/372 [=========>....................] - ETA: 3s - accuracy: 0.7943 - loss: 0.94140/372 [==========>...................] - ETA: 3s - accuracy: 0.7951 - loss: 0.94144/372 [==========>...................] - ETA: 2s - accuracy: 0.7939 - loss: 0.94149/372 [===========>..................] - ETA: 2s - accuracy: 0.7931 - loss: 0.95154/372 [===========>..................] - ETA: 2s - accuracy: 0.7926 - loss: 0.95158/372 [===========>..................] - ETA: 2s - accuracy: 0.7927 - loss: 0.95162/372 [============>.................] - ETA: 2s - accuracy: 0.7931 - loss: 0.95167/372 [============>.................] - ETA: 2s - accuracy: 0.7934 - loss: 0.94172/372 [============>.................] - ETA: 2s - accuracy: 0.7936 - loss: 0.94177/372 [=============>................] - ETA: 2s - accuracy: 0.7944 - loss: 0.94182/372 [=============>................] - ETA: 2s - accuracy: 0.7942 - loss: 0.94187/372 [==============>...............] - ETA: 2s - accuracy: 0.7937 - loss: 0.94192/372 [==============>...............] - ETA: 2s - accuracy: 0.7926 - loss: 0.95197/372 [==============>...............] - ETA: 2s - accuracy: 0.7931 - loss: 0.95202/372 [===============>..............] - ETA: 2s - accuracy: 0.7924 - loss: 0.95207/372 [===============>..............] - ETA: 2s - accuracy: 0.7924 - loss: 0.95212/372 [================>.............] - ETA: 2s - accuracy: 0.7932 - loss: 0.94216/372 [================>.............] - ETA: 1s - accuracy: 0.7930 - loss: 0.94220/372 [================>.............] - ETA: 1s - accuracy: 0.7928 - loss: 0.94224/372 [=================>............] - ETA: 1s - accuracy: 0.7933 - loss: 0.94228/372 [=================>............] - ETA: 1s - accuracy: 0.7930 - loss: 0.94232/372 [=================>............] - ETA: 1s - accuracy: 0.7929 - loss: 0.94237/372 [==================>...........] - ETA: 1s - accuracy: 0.7928 - loss: 0.94242/372 [==================>...........] - ETA: 1s - accuracy: 0.7923 - loss: 0.94247/372 [==================>...........] - ETA: 1s - accuracy: 0.7938 - loss: 0.93252/372 [===================>..........] - ETA: 1s - accuracy: 0.7935 - loss: 0.93256/372 [===================>..........] - ETA: 1s - accuracy: 0.7931 - loss: 0.94261/372 [====================>.........] - ETA: 1s - accuracy: 0.7924 - loss: 0.94266/372 [====================>.........] - ETA: 1s - accuracy: 0.7919 - loss: 0.94271/372 [====================>.........] - ETA: 1s - accuracy: 0.7917 - loss: 0.94276/372 [=====================>........] - ETA: 1s - accuracy: 0.7920 - loss: 0.94281/372 [=====================>........] - ETA: 1s - accuracy: 0.7920 - loss: 0.94286/372 [======================>.......] - ETA: 1s - accuracy: 0.7915 - loss: 0.94290/372 [======================>.......] - ETA: 1s - accuracy: 0.7913 - loss: 0.95294/372 [======================>.......] - ETA: 0s - accuracy: 0.7913 - loss: 0.95298/372 [=======================>......] - ETA: 0s - accuracy: 0.7907 - loss: 0.95302/372 [=======================>......] - ETA: 0s - accuracy: 0.7908 - loss: 0.95306/372 [=======================>......] - ETA: 0s - accuracy: 0.7911 - loss: 0.95310/372 [========================>.....] - ETA: 0s - accuracy: 0.7912 - loss: 0.95314/372 [========================>.....] - ETA: 0s - accuracy: 0.7912 - loss: 0.95318/372 [========================>.....] - ETA: 0s - accuracy: 0.7918 - loss: 0.94322/372 [========================>.....] - ETA: 0s - accuracy: 0.7920 - loss: 0.94326/372 [=========================>....] - ETA: 0s - accuracy: 0.7921 - loss: 0.94331/372 [=========================>....] - ETA: 0s - accuracy: 0.7924 - loss: 0.94336/372 [==========================>...] - ETA: 0s - accuracy: 0.7926 - loss: 0.94341/372 [==========================>...] - ETA: 0s - accuracy: 0.7929 - loss: 0.94345/372 [==========================>...] - ETA: 0s - accuracy: 0.7929 - loss: 0.94349/372 [===========================>..] - ETA: 0s - accuracy: 0.7925 - loss: 0.94353/372 [===========================>..] - ETA: 0s - accuracy: 0.7925 - loss: 0.94357/372 [===========================>..] - ETA: 0s - accuracy: 0.7928 - loss: 0.94361/372 [============================>.] - ETA: 0s - accuracy: 0.7923 - loss: 0.94365/372 [============================>.] - ETA: 0s - accuracy: 0.7923 - loss: 0.94369/372 [============================>.] - ETA: 0s - accuracy: 0.7922 - loss: 0.94372/372 [==============================] - 6s 15ms/step - accuracy: 0.7923 - loss: 0.9402 - val_accuracy: 0.4256 - val_loss: 1.5572\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Trial ID: 750a4a5070203d91bf578e6a37196efb</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Score: 0.42559725046157837</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-Best step: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_1_dropout: 0.40000000000000013</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_1_units: 216</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-layer_2_dropout: 0.20000000000000004</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-layer_2_units: 64</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/bracket: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/epochs: 2</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\nINFO:tensorflow:Error reported to Coordinator: \nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\n    yield\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py\", line 165, in _call_for_each_replica\n    t.has_paused.wait()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 552, in wait\n    signaled = self._cond.wait(timeout)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\threading.py\", line 296, in wait\n    waiter.acquire()\nKeyboardInterrupt\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-29d5de719a87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstatic_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"VAL_SPLIT\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"logs/fit\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\kerastuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\kerastuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'epochs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tuner/epochs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'initial_epoch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tuner/initial_epoch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\kerastuner\\engine\\multi_execution_tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_fit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_values\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'min'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                     \u001b[0muser_requested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m                 ))\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctionScope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fscope'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConversionOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_requested\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minternal_convert_user_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduce_per_replica\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    416\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_in_whitelist_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Whitelisted %s: from cache'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    949\u001b[0m       fn = autograph.tf_convert(\n\u001b[0;32m    950\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m--> 951\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    952\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m   \u001b[1;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2288\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2289\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2290\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m     return _call_for_each_replica(self._container_strategy(), self._devices,\n\u001b[1;32m--> 770\u001b[1;33m                                   fn, args, kwargs)\n\u001b[0m\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m   def _configure(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(distribution, devices, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m       \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_result\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\u001b[0m in \u001b[0;36mstop_on_exception\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m       \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=bare-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[1;34m(distribution, devices, fn, args, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m             \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_paused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=static_params[\"VAL_SPLIT\"],\n",
    "    epochs=250,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping('val_accuracy')] #tensorboard_callback(\"logs/fit/\" + timestamp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hyper_results/SEG/tuner.pkl\", 'wb') as f:\n",
    "    dill.dump(tuner, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}